Read data/GEMSGD_T5TokenizerFast_SGD_PaperNaiveLinearizer_train
Read data/GEMSGD_T5TokenizerFast_SGD_PaperNaiveLinearizer_val
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/root/SGD_NLG/tests/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(

  | Name  | Type       | Params | Mode
---------------------------------------------
0 | model | PT_T5Model | 68.2 M | train
---------------------------------------------
7.7 M     Trainable params
60.5 M    Non-trainable params
68.2 M    Total params
272.806   Total estimated model params size (MB)
18        Modules in train mode
277       Modules in eval mode
Epoch 4: 100%|â–ˆ| 20623/20623 [1:49:28<00:00,  3.14it/s, v_num=_pos, train_loss=0.                                                                                                             
/root/SGD_NLG/tests/lib/python3.10/site-packages/transformers/modeling_utils.py:1126: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.
  warnings.warn(
/root/SGD_NLG/tests/lib/python3.10/site-packages/transformers/modeling_utils.py:1080: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.
  warnings.warn(
                                                                                                                                                                                              
`Trainer.fit` stopped: `max_epochs=5` reached.
